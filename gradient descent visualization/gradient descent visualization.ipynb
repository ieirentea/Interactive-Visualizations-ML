{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "078cc4ab",
   "metadata": {},
   "source": [
    "# Gradient Descent\n",
    "This is the link for the survey: https://forms.office.com/e/qPaLAwcPEG\n",
    "\n",
    "This activity is intended to help you:\n",
    "- Remember how gradient descent works\n",
    "- Understand how gradient descent is applied\n",
    "- Apply gradient descent\n",
    "\n",
    "Gradient descent is a searching algorithm, which, in the context of machine learning, can be used to search for the parameter value linked to the minimum cost. This algorithm is ideal when the function shape or optimum is unknown.\n",
    "\n",
    "The gradient descent algorithm, as its name suggests, relies on the gradient of a given function. Namely, it updates a certain variable with the gradient of a loss function in the given point multiplied by the chosen learning rate. \n",
    "\n",
    "The algorithm's steps are the following:\n",
    "1. Pick a random starting point $w_0$\n",
    "2. Updates the variable according to the following update rule:\n",
    "    $w_j^{t+1} = w_j^t-\\alpha\\frac{\\partial J(w,w_0)}{\\partial w_j}\\Bigr|_{w, w_0 = w^t, w_0^t}$\n",
    "    where $\\alpha$ = learning rate, $w_j^t$ = j-th parameter's value at step t\n",
    "    \n",
    "Let's pick the cost function to be the mean squared error:\n",
    "    $J(w, w_0) = \\frac{1}{N}\\sum_{i=1}^{N}(x_i^Tw + w_0 - y_i)^2$\n",
    "    \n",
    "Then the gradient is the following:\n",
    "    $\\frac{\\partial J(w, w_0)}{\\partial w_j} = \\frac{1}{N}\\sum_{i=1}^{N}2(x_i^Tw + w_0 - y_i)x_i^{(j)}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f13a77c",
   "metadata": {},
   "source": [
    "---\n",
    "Running the following code will generate a visualization showing the gradient descent algorithm for functions with one variable. \n",
    "\n",
    "You can interact with the visualization by changing the loss function, starting value for x, learning rate, and amount of computed iterations of the algorithm. \n",
    "\n",
    "You can also choose to see the visual interpretation of the gradient used for the last update of the algorithm. \n",
    "\n",
    "Also, above the graph you can see the mathematical calculation used for the last update.\n",
    "\n",
    "Note: for the custom function start with a value around 0(+-0.2) to observe the correct behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4880005b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cc9e1b5dd224e55afdad96c31af46fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FloatSlider(value=2.0, continuous_update=False, description='Starting Value:', layout=Layout(wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3856185028a84dc99f88c294efd35077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from GD_utils import GD_2D, GD_3D, GD_manual\n",
    "plot = GD_2D()\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7412dd1f",
   "metadata": {},
   "source": [
    "---\n",
    "Similar to the previous step, you should run the following code to generate a visualization for gradient descent for a function with six variables.\n",
    "\n",
    "The first graph shows the dataset used for the algorithm.\n",
    "\n",
    "The second graph shows the evolution of the mean squared error.\n",
    "\n",
    "Your task is to manipulate the value of each variable based on the gradient shown on its right. You don't need to perfectly match the data points, but try to make the line as close as you can while observing the evolution of the gradients and of the mean squared error.\n",
    "\n",
    "During your interaction, think about how the gradient descent algorithm would work in this context and try to imitate the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b9690e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2c043e7a7df4df9855b8c5b4bc3a1ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(FloatSlider(value=0.0, continuous_update=False, max=10.0, min=-10.0), Label(valu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a3be918096433ba915d05a96663a97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot = GD_manual()\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f889237e",
   "metadata": {},
   "source": [
    "---\n",
    "Similar to the previous step, you should run the following code to generate a visualization for gradient descent for a function with two variables(a and b).\n",
    "\n",
    "The first graph shows the dataset used for the algorithm. The optimization problem tries to fit a line with the function $a*x+b$.\n",
    "\n",
    "The second graph shows the values of the loss function depending on the values of a and b.\n",
    "\n",
    "The third graph shows the evolution of the mean squared error over the computed epochs.\n",
    "\n",
    "You can interact with the visualization by changing the starting values of a and b, learning rate and number of epochs computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55bb2eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4dbd3d4e2fb4bd0859980ef5cb3f22b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(FloatSlider(value=-10.0, continuous_update=False, description='Starting value a'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a67872f94664af0ad65cefe2787d719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot = GD_3D()\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8446430e",
   "metadata": {},
   "source": [
    "---\n",
    "This is the end of the instructional materials for the gradient descent part.\n",
    "\n",
    "To summarise, gradient descent is an algorithm that aims to find the minimum of a loss function using the gradient of the function. The algorithm constantly performs updates, until it find the minimum of the function.\n",
    "\n",
    "You can now take a last look at the detailed description from the beginning and at the visualizations, before returing to the survey."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
